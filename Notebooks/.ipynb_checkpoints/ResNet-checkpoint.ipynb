{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f336f40-df02-4428-816c-e5ea8cf7775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "TRAIN_DIR = '../EmotionsDataset/train/'\n",
    "TEST_DIR = '../EmotionsDataset/test/'\n",
    "CLASS_NAMES = ['angry','happy','sad']\n",
    "# Updated Configuration\n",
    "CONFIGURATION = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'IM_SIZE': 256,\n",
    "    'N_EPOCHS': 30,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcd05f61-a038-47cd-bf5e-f71a0cce2017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6799 files belonging to 3 classes.\n",
      "Found 2278 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=None,\n",
    "    subset=None\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory=TEST_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=None,\n",
    "    subset=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfd42f80-eb35-442d-9584-34c33f46e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback,CSVLogger,EarlyStopping\n",
    "csv_logger = CSVLogger(\"renetLogs.csv\",separator=',',append=False)\n",
    "es_callback = EarlyStopping(restore_best_weights=True,patience=2)\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "sched = LearningRateScheduler(scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6d77628-41cd-49e3-83d7-0e1e1a713959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize images to 224x224\n",
    "    image = tf.cast(image, tf.float32)  # Convert images to float32\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "# Normalization function\n",
    "def normalise(image, label):\n",
    "    return image / 255.0, label\n",
    "\n",
    "# Apply normalization\n",
    "train_dataset = train_dataset.map(normalise)\n",
    "test_dataset = test_dataset.map(normalise)\n",
    "\n",
    "# # Apply shuffling, batching, and prefetching\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "# test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39568df1-6760-4a5e-834a-1e643ec8f0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7aef6f4b-65d4-4fa0-be52-f9b581188972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add,Conv2D,Layer, MaxPooling2D, Dense, InputLayer, Flatten, BatchNormalization, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "class CustomConv2D(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding='valid'): # Add data_format\n",
    "        super(CustomConv2D, self).__init__()\n",
    "        self.conv2D = Conv2D(filters, kernel_size, strides, padding=padding) # Set data_format for Conv2D\n",
    "        self.batchNorm = BatchNormalization()\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        # Ensure x is of shape (batch_size, height, width, channels)\n",
    "        x = self.conv2D(x)\n",
    "        x = self.batchNorm(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aeeb3657-2d2e-4309-9bf1-a2719e3ca610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, n_channels, n_strides=1):\n",
    "        super(ResidualBlock, self).__init__(name=\"residual_layer\")\n",
    "        self.dotted = (n_strides != 1) or (n_channels != 3)  # Adjust the check for the number of channels\n",
    "        self.custom_conv_1 = CustomConv2D(n_channels, 3, n_strides, padding=\"same\")\n",
    "        self.custom_conv_2 = CustomConv2D(n_channels, 3, 1, padding=\"same\")\n",
    "        self.activation = Activation(\"relu\")\n",
    "        \n",
    "        if self.dotted:\n",
    "            self.custom_conv_3 = CustomConv2D(n_channels, 1, n_strides)\n",
    "\n",
    "    def call(self, Input, training=False):\n",
    "        x = self.custom_conv_1(Input, training=training)\n",
    "        x = self.custom_conv_2(x, training=training)\n",
    "        \n",
    "        if self.dotted:\n",
    "            x_add = self.custom_conv_3(Input, training=training)\n",
    "            x_add = Add()([x, x_add])\n",
    "        else:\n",
    "            x_add = Add()([x, Input])\n",
    "        \n",
    "        return self.activation(x_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "036026ca-9f2e-4ec3-aeaa-b0213bba6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf # Import tensorflow\n",
    "\n",
    "class ResNet34(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet34, self).__init__(name=\"resnet_34\")\n",
    "        # Input layer with explicit input shape\n",
    "        self.conv_1 = CustomConv2D(67,3,2, padding='same')\n",
    "        self.max_pool = MaxPooling2D(3, 2)\n",
    "\n",
    "        # Residual Layers\n",
    "        self.conv_2_1 = ResidualBlock(64)\n",
    "        self.conv_2_2 = ResidualBlock(64)\n",
    "        self.conv_2_3 = ResidualBlock(64)\n",
    "        \n",
    "        self.conv_3_1 = ResidualBlock(128, 2)\n",
    "        self.conv_3_2 = ResidualBlock(128)\n",
    "        self.conv_3_3 = ResidualBlock(128)\n",
    "        \n",
    "        self.conv_4_1 = ResidualBlock(256, 2)\n",
    "        self.conv_4_2 = ResidualBlock(256)\n",
    "        self.conv_4_3 = ResidualBlock(256)\n",
    "        \n",
    "        self.conv_5_1 = ResidualBlock(512, 2)\n",
    "        self.conv_5_2 = ResidualBlock(512)\n",
    "        self.conv_5_3 = ResidualBlock(512)\n",
    "\n",
    "        # Global Average Pooling and Fully Connected\n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        self.fc = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.conv_2_1(x, training=training)\n",
    "        x = self.conv_2_2(x, training=training)\n",
    "        x = self.conv_2_3(x, training=training)\n",
    "\n",
    "        x = self.conv_3_1(x, training=training)\n",
    "        x = self.conv_3_2(x, training=training)\n",
    "        x = self.conv_3_3(x, training=training)\n",
    "\n",
    "        x = self.conv_4_1(x, training=training)\n",
    "        x = self.conv_4_2(x, training=training)\n",
    "        x = self.conv_4_3(x, training=training)\n",
    "\n",
    "        x = self.conv_5_1(x, training=training)\n",
    "        x = self.conv_5_2(x, training=training)\n",
    "        x = self.conv_5_3(x, training=training)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "673be1a1-a0ac-482a-ae31-fe69abc8f407",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling ResNet34.call().\n\n\u001b[1mInput 0 of layer \"max_pooling2d_16\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 224, 3)\u001b[0m\n\nArguments received by ResNet34.call():\n  • x=tf.Tensor(shape=(224, 224, 3), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet34(num_classes\u001b[38;5;241m=\u001b[39mCONFIGURATION[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUM_CLASSES\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Build the model (define the input shape accordingly)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Example input shape with batch size 1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[79], line 33\u001b[0m, in \u001b[0;36mResNet34.call\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_2_1(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_2_2(x, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling ResNet34.call().\n\n\u001b[1mInput 0 of layer \"max_pooling2d_16\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 224, 3)\u001b[0m\n\nArguments received by ResNet34.call():\n  • x=tf.Tensor(shape=(224, 224, 3), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "source": [
    "model = ResNet34(num_classes=CONFIGURATION['NUM_CLASSES'])\n",
    "# Build the model (define the input shape accordingly)\n",
    "model(tf.zeros([1,224, 224, 3]),training= False)  # Example input shape with batch size 1\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f201820-9b08-4817-9e02-935f4e084549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=[CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f6d41-f241-4960-aa25-9addbb277ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'resnet_34', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726939211.241789    3619 service.cc:146] XLA service 0x7f7c0c003ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726939211.245877    3619 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-09-21 17:20:14.259500: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# When defining the input, ensure you have the correct shape\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "\n",
    "# Now train your model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=30,\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[csv_logger, es_callback, sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ac95c-a39f-4c11-9ac5-dbee6dd05783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d17c75-5843-4536-9cec-29c140ef9869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
