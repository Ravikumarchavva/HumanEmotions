{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59665db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 06:13:57.163513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-12 06:13:57.178583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-12 06:13:57.183174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-12 06:13:57.195229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728713640.264469    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713640.271891    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713640.271973    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable memory growth to allocate only as needed\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Alternatively, set a memory limit if you want to control the allocation\n",
    "# Uncomment the lines below and adjust the limit as needed\n",
    "memory_limit = 4096  # Set memory limit in MB (e.g., 4GB)\n",
    "tf.config.set_logical_device_configuration(\n",
    "    gpu,\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942bf161-34cf-43d5-bd12-2412ff28457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6799 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728713646.245332    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713646.245429    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713646.245456    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713646.352004    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-12 06:14:06.352042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728713646.352098    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728713646.352128    1107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-12 06:14:06.352155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2280 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Updated Configuration\n",
    "CONFIGURATION = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'IM_SIZE': 224,\n",
    "    'N_EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'NUM_CLASSES': 3,\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    '../../EmotionsDataset/train/',\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    '../../EmotionsDataset/test/',\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "def build_model(config):\n",
    "    base_model = EfficientNetB0(include_top=False, input_shape=(config['IM_SIZE'], config['IM_SIZE'], 3), weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(config['NUM_CLASSES'], activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(CONFIGURATION)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIGURATION['LEARNING_RATE']),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9d464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728713666.019834    1188 service.cc:146] XLA service 0xe8aadc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728713666.019923    1188 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-10-12 06:14:26.345215: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-12 06:14:27.597482: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-12 06:14:30.012597: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11307', 148 bytes spill stores, 148 bytes spill loads\n",
      "\n",
      "2024-10-12 06:14:30.518323: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12006', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-12 06:14:30.659342: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12006', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-10-12 06:14:30.684880: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12006', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-10-12 06:14:30.765578: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12006', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1728713687.249268    1188 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m212/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4866 - loss: 1.4309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 06:15:00.802082: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11307', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.4869 - loss: 1.4298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 06:15:27.649861: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2074', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 236ms/step - accuracy: 0.4872 - loss: 1.4287 - val_accuracy: 0.6531 - val_loss: 0.7695\n",
      "Epoch 2/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.6210 - loss: 0.9166 - val_accuracy: 0.7373 - val_loss: 0.6371\n",
      "Epoch 3/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.6825 - loss: 0.7630 - val_accuracy: 0.7500 - val_loss: 0.6029\n",
      "Epoch 4/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7021 - loss: 0.6942 - val_accuracy: 0.7592 - val_loss: 0.5783\n",
      "Epoch 5/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7238 - loss: 0.6470 - val_accuracy: 0.7724 - val_loss: 0.5622\n",
      "Epoch 6/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7313 - loss: 0.6236 - val_accuracy: 0.7772 - val_loss: 0.5610\n",
      "Epoch 7/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7393 - loss: 0.6132 - val_accuracy: 0.7706 - val_loss: 0.5635\n",
      "Epoch 8/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7422 - loss: 0.5952 - val_accuracy: 0.7649 - val_loss: 0.5701\n",
      "Epoch 9/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.7553 - loss: 0.5870 - val_accuracy: 0.7768 - val_loss: 0.5435\n",
      "Epoch 10/10\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7615 - loss: 0.5707 - val_accuracy: 0.7829 - val_loss: 0.5364\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7889 - loss: 0.5282\n",
      "Test Loss: 0.5364, Test Accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=CONFIGURATION['N_EPOCHS']\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9401e953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object representative_data_gen at 0x7f3e662468e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value, _ in train_dataset.take(1):\n",
    "        yield [input_value]\n",
    "representative_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640e9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvxe46hw2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvxe46hw2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpvxe46hw2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_238')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139903579454160: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  139903579455120: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  139903579454736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459148432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459148240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903579455312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459149008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459150160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459150544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459148048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459150736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459149968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459154000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459153232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459154960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459153808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459155728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459154768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459153616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459154576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459155344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459157648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459153424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459157264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459156688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459157072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459159760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459155536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459159376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459158800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459159184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459161872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459158032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459162832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459161680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459163792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459162448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393628816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459162640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903459163408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393629776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393629200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393628432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393628624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393629392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393631696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393631120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393630352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393629008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393631312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393633616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393630736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393634384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393633232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393635152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393634192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393632272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393634000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393634768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393637456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393636880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393636496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393636688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393637072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393639376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393638800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393638032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393634960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393638992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393641296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393638416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393642064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393640912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393642832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393641872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393639952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393641680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393642448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393644368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394218064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394218448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393643792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903393640336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394220176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394219600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394218832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394218256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394219792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394222096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394219216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394222864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394221712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394223632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394222672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394220752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394222480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394223248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394225936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394225360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394224976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394225168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394225552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394227856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394227280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394226512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394223440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394227472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394229776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394226896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394230544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394229392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394231312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394230352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394228432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394230160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394230928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394233232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394232656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394231888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394228816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394232848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903394233040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192515024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192515408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192514832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192515600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192517328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192514640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192518096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192516944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192518864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192517904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192515984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192517712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192518480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192521168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192520592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192520208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192520400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192520784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192523088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192522512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192521744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192518672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192522704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192525008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192522128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192525776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192524624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192526544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192525584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192523664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192525392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192526160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192528848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192528272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192527888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192528080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192528464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192530768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192526352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921556240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192529808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139903192530384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921557776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921556432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921558544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921557392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921559312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921558352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921556624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921558160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921558928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921561232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921560656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921559888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921556816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921560848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921563152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921562576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921561808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921560272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921562768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921565072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921562192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921565840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921564688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921566608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921565648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921563728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921565456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921566224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921568912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921568336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921567952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921568144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921568528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921570832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921570256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921569488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921566416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921570448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921572176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902921569872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922080528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922080912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922082256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922081296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922081680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922081488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922081872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922084560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922083984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922083600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922083792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922084176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922086480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922085904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922085136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922082064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922086096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922088400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922085520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922089168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922088016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922089936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922088976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922087056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922088784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922089552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922091856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922091280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922090512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922087440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922091472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922093200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922092432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922090896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922093392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922095696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922092816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922096464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922094736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922095504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607032784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607032592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902922095312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607032400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607035280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607034704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607034320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607034512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607034896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607037200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607036624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607035856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607033168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607036816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607039120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607036240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607039888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607038736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607040656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607037776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607039504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607040272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607042000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607042192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607042576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607044880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607044304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607043536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607046800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607043920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607047568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607046416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607048336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607045456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607688336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607047184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607047952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607689872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607689296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607688912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607689104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607689488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607691792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607691216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607690448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607687952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607691408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607693712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607690832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607694480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607693328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607695248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607694288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607692368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607694096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607694864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607697168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607696592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607695824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607692752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607696784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607702352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607703312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320608848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320609232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902607703888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320607312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320608656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320610000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320611152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320611536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320610384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320610768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320610960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139902320612304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1728724488.727876    1107 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1728724488.728076    1107 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-10-12 09:14:48.728775: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvxe46hw2\n",
      "2024-10-12 09:14:48.755583: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-10-12 09:14:48.755639: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpvxe46hw2\n",
      "2024-10-12 09:14:49.092015: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-10-12 09:14:50.954270: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpvxe46hw2\n",
      "2024-10-12 09:14:51.456571: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 2727805 microseconds.\n",
      "2024-10-12 09:31:30.068059: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "def representative_data_gen():\n",
    "    for input_value, _ in train_dataset.take(100):\n",
    "        yield [input_value]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228672df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f843a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2024-10-12 08:58:15,252 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728723496.370022    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723496.474272    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723496.474472    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723496.502478    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723496.502671    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723496.502808    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723497.336517    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723497.336873    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728723497.337181    1761 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-12 08:58:17,360 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tf2onnx/convert.py\", line 714, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tf2onnx/convert.py\", line 242, in main\n",
      "    graph_def, inputs, outputs, initialized_tables, tensors_to_rename = tf_loader.from_saved_model(\n",
      "                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tf2onnx/tf_loader.py\", line 636, in from_saved_model\n",
      "    _from_saved_model_v2(model_path, input_names, output_names,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tf2onnx/tf_loader.py\", line 570, in _from_saved_model_v2\n",
      "    imported = tf.saved_model.load(model_path, tags=tag)  # pylint: disable=no-value-for-parameter\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\", line 912, in load\n",
      "    result = load_partial(export_dir, None, tags, options)[\"root\"]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\", line 1016, in load_partial\n",
      "    loader_impl.parse_saved_model_with_debug_info(export_dir))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 59, in parse_saved_model_with_debug_info\n",
      "    saved_model = parse_saved_model(export_dir)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 119, in parse_saved_model\n",
      "    raise IOError(\n",
      "OSError: SavedModel file does not exist at: effnetmodel/{saved_model.pbtxt|saved_model.pb}\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model effnetmodel --output effnetmodel.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da3211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet = 'effnetmodel.keras'\n",
    "model.save(effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c32912c-533e-40f0-8c57-52041ead1638",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"dense\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1258>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1259>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load your Keras model (.h5 format)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m effnet \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meffnetmodel.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43meffnet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py:182\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    179\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:237\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:314\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 314\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    319\u001b[0m weights_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:303\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 303\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py:351\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m         layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    348\u001b[0m             layer_config,\n\u001b[1;32m    349\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    350\u001b[0m         )\n\u001b[0;32m--> 351\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_functional\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m    356\u001b[0m ):\n\u001b[1;32m    357\u001b[0m     model\u001b[38;5;241m.\u001b[39mbuild(build_input_shape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:225\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    224\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 225\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py:160\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"dense\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1258>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1259>]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "# Load your Keras model (.h5 format)\n",
    "effnet = 'effnetmodel.keras'\n",
    "model = tf.keras.models.load_model(effnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae70c4-0d21-4748-8bb3-a3645586d00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
