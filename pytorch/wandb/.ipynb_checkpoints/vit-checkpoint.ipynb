{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.18.3-py3-none-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (4.25.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chavv\\anaconda\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.18.3-py3-none-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB 495.5 kB/s eta 0:00:26\n",
      "    --------------------------------------- 0.2/12.6 MB 1.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/12.6 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.6/12.6 MB 2.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.6/12.6 MB 2.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/12.6 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/12.6 MB 2.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.2/12.6 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.2/12.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 2.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.7/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.0/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.2/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.3/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.5/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.7/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.7/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.0/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.1/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.2/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.5/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.6/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.8/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.0/12.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.1/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.3/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.4/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.5/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.6/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.8/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.9/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.1/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.3/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.4/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.6/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.7/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.8/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.9/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.0/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.2/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.3/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.4/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.5/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.6/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.8/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.9/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.0/12.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.2/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.5/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.6/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.7/12.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.8/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.0/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.2/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.3/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.5/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.6/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.8/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.1/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.3/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.5/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.6/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.8/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.9/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.0/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.1/12.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.3/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.6/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.1/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.2/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.7/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.0/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.2/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl (313 kB)\n",
      "   ---------------------------------------- 0.0/313.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 143.4/313.8 kB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 256.0/313.8 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 313.8/313.8 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.3-cp39-cp39-win_amd64.whl (11 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, click, gitdb, gitpython, wandb\n",
      "Successfully installed click-8.1.7 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.16.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "# Login to Weights & Biases using the API key\n",
    "try:\n",
    "    wandb.login(key=api_key)\n",
    "    print(\"Logged in successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during login: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/Notebooks/wandb/wandb/run-20241010_131616-jxpdqecr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation/runs/jxpdqecr' target=\"_blank\">human-pose-estimation</a></strong> to <a href='https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation' target=\"_blank\">https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation/runs/jxpdqecr' target=\"_blank\">https://wandb.ai/ravikumarchavva-org/transformers-human-pose-estimation/runs/jxpdqecr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updated Configuration\n",
    "CONFIGURATION = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'IM_SIZE': 224,\n",
    "    'N_EPOCHS': 30,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 3,\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"transformers-human-pose-estimation\",\n",
    "\n",
    "    # Set the experiment name\n",
    "    name=\"human-pose-estimation\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": CONFIGURATION['LEARNING_RATE'],\n",
    "        \"epochs\": CONFIGURATION['N_EPOCHS'],\n",
    "        \"batch_size\": CONFIGURATION['BATCH_SIZE'],\n",
    "        \"image_size\": CONFIGURATION['IM_SIZE'],\n",
    "        \"num_classes\": CONFIGURATION['NUM_CLASSES'],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../../EmotionsDataset/train/'\n",
    "TEST_DIR = '../../EmotionsDataset/test/'\n",
    "CLASS_NAMES = ['angry','happy','sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 569, in reduce_storage\n",
      "    fd, size = storage._share_fd_cpu_()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/storage.py\", line 407, in _share_fd_cpu_\n",
      "    return super()._share_fd_cpu_(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: unable to write to file </torch_2197_1867393913_1>: No space left on device (28)\n",
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m\n\u001b[1;32m     47\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     48\u001b[0m     test_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m     generator\u001b[38;5;241m=\u001b[39mgenerator  \u001b[38;5;66;03m# Use the same CPU-based generator\u001b[39;00m\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Check a batch of data\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure data is on the correct device (GPU/CPU)\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage batch shape: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (Batch size, Channels, Height, Width)\u001b[39;49;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1873, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 67, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 2210) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Ensure you have the correct device set\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define image size and normalization parameters\n",
    "IMAGE_SIZE = CONFIGURATION['IM_SIZE']  # Example: 224\n",
    "BATCH_SIZE = CONFIGURATION['BATCH_SIZE']  # Example: 32\n",
    "\n",
    "# Define the transformations for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize images to the desired size\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (ImageNet mean & std)\n",
    "])\n",
    "\n",
    "# Create a CPU-based generator (consistent across all DataLoaders)\n",
    "generator = torch.Generator(device='cpu')\n",
    "\n",
    "# Custom Dataset class to apply preprocessing and normalization\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(image_folder)  # Load images using ImageFolder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]  # Retrieve image and label\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations (resize, normalization, etc.)\n",
    "        return image, label\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = CustomImageDataset(image_folder=TRAIN_DIR, transform=transform)\n",
    "test_dataset = CustomImageDataset(image_folder=TEST_DIR, transform=transform)\n",
    "\n",
    "# Create DataLoaders for shuffling, batching, and prefetching\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True,\n",
    "    generator=generator  # Use a CPU-based generator for consistency\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True,\n",
    "    generator=generator  # Use the same CPU-based generator\n",
    ")\n",
    "\n",
    "# Check a batch of data\n",
    "for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)  # Ensure data is on the correct device (GPU/CPU)\n",
    "    print(f\"Image batch shape: {images.shape}\")  # (Batch size, Channels, Height, Width)\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
