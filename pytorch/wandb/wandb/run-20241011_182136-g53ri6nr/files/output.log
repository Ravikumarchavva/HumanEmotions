Number of training samples: 6799
Number of testing samples: 2280
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\chavv\anaconda\envs\huggingface-torch\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1/10
Batch 0/213 - Loss: 1.1111
Batch 10/213 - Loss: 1.0612
Batch 20/213 - Loss: 1.0658
Batch 30/213 - Loss: 1.0149
Batch 40/213 - Loss: 1.0504
Batch 50/213 - Loss: 0.9859
Batch 60/213 - Loss: 1.0213
Batch 70/213 - Loss: 1.1017
Batch 80/213 - Loss: 1.0895
Batch 90/213 - Loss: 1.0855
Batch 100/213 - Loss: 1.1026
Batch 110/213 - Loss: 1.0569
Batch 120/213 - Loss: 1.0274
Batch 130/213 - Loss: 1.0063
Batch 140/213 - Loss: 1.0654
Batch 150/213 - Loss: 1.1003
Batch 160/213 - Loss: 1.0187
Batch 170/213 - Loss: 1.0187
Batch 180/213 - Loss: 1.1078
Batch 190/213 - Loss: 1.1469
Batch 200/213 - Loss: 1.0447
Batch 210/213 - Loss: 1.0979
Training loss: 1.0652, Accuracy: 0.4392, Top-2 Accuracy: 0.7711
Validation loss: 1.0659, Accuracy: 0.4412, Top-2 Accuracy: 0.7732
Epoch 2/10
Batch 0/213 - Loss: 1.0795
Batch 10/213 - Loss: 1.1266
Batch 20/213 - Loss: 1.1806
Batch 30/213 - Loss: 1.0840
Batch 40/213 - Loss: 1.0253
Batch 50/213 - Loss: 1.0171
Batch 60/213 - Loss: 1.0811
